---
title: "Tutorial Part II — R goes Spatial"
author: "Stephanie Kramer-Schadt"
date: "`r Sys.setlocale('LC_TIME','C'); paste('Last Update', format(Sys.time(), '%B %e, %Y')) `" 
output:
  rmdformats::readthedown:
    highlight: kate
    code_folding: show
    toc_depth: 4
    toc_float: true
editor_options:
  chunk_output_type: console
params:
  date: !r Sys.Date()
---

<style>
h1, h2, h3 {
  margin-top: 50px;
}
h1 {
  color: Orange ;
}
h2, h3, h4, h5, h6, legend {
  color: Indigo ;
}
p {
  line-height:170%;
}
sidebar h2 {
  background-color: Indigo;
}
code {
  color: Indigo ;
}
.exercise {
  color: #824b00;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      fig.width = 9, fig.height = 6, dev = "ragg_png")
#knitr::opts_knit$set(root.dir = 'C:/Users/kramer/PopDynIZW Dropbox/Steph Kramer/_GitHub')
```

```{r}
## this might be useful if rtools is not yet installed manually
#install.packages("installr")
#installr::install.rtools()
```


Let me start with a big thanks to Cedric Scherer, Moritz Wenzler, Pierre Gras and Juergen
Niedballa who constantly helped to improve the course since its start in 2014! 
I am deeply indebted to you!

# Introduction

The course is intended to be a quick introduction to using R as a GIS. It builds
on the previous course, Course1_RIntro, and is written in such a way that you can
understand handling spatial data when knowing the basics of handling data.frames,
matrices and lists. There is no need to know `tidyverse/dplyr` coding style.

This course provides the basics for using the most important spatial
data types — vector data (points, lines, polygons, aka ESRI shapefiles) and raster data.

Recently, `{sf}` objects have been developed to handle vector data more easily. Those
objects can be treated like simple `data.frames`. For raster data there are fast and modern
packages — namely `{terra}` and `{stars}`. The `{terra}` package is also especially useful 
for remote sensing data; it has a single `SpatRaster` class. 
The course is updated to use the `{terra}` package. 

In addition to different data types, the course provides sections on coordinate
projections and the most important geo-spatial operations. Last but not least -
we plot a lot of maps to ease data visualization and because it is fun.

The data we use stem from a longstanding project we run in Borneo. Please refer to
our website [https://ecodynizw.github.io/](https://ecodynizw.github.io/) for further information.
The project involves species conservation and large scale landscape planning. To
learn more about the data used in the course and the project, please refer to the
following publications that are freely available:

* Targeted conservation to safeguard a biodiversity hotspot from climate and land-cover change.
MJ Struebig, et al. 2015. Current Biology 25 (3), 372-378. https://doi.org/10.1016/j.cub.2014.11.067

* Anticipated climate and land‐cover changes reveal refuge areas for Borneo's orang-utans.
MJ Struebig, et al. 2015. Global Change Biology 21 (8), 2891-2904. https://doi.org/10.1111/gcb.12814

* The importance of correcting for sampling bias in MaxEnt species distribution models.
S Kramer‐Schadt et al. 2013. Diversity and Distributions 19 (11), 1366-1379. https://doi.org/10.1111/ddi.12096

* The Borneo carnivore database and the application of predictive distribution modelling.
S Kramer-Schadt, et al.2016. Raffles Bulletin of Zoology, Supplement No. 33: 18–41. 
https://lkcnhm.nus.edu.sg/app/uploads/2017/06/S33rbz018-041-1.pdf


## Useful (web)sites

**1. R news and tutorials**  

* http://www.r-bloggers.com/  

**2. Quick introduction to spatial R**

* https://rspatial.org/   
* https://r-spatial.org/ 

**3. Spatial visualisation**

* check out the packages `{tmap}`, `{ggmap}`, `{leaflet}` and `{cartography}`  
* https://r-tmap.github.io/tmap/    
* A whole book: https://clauswilke.com/dataviz/ with spatial data here: 
  https://clauswilke.com/dataviz/geospatial-data.html 
* and my all-time favourite: https://www.cedricscherer.com/
  
**4. Overview of spatial packages** 

* http://cran.r-project.org/web/views/Spatial.html =  <br>   http://cran.r-project.org/view=Spatial  


**5. R-cheatsheets — great for learning 'vocabulary'**  
* e.g. here: https://www.rstudio.com/resources/cheatsheets/  and click on 'contributed cheatsheets'  

**6. Infos about simple features in R (`{sf}` package)**  

*  https://r-spatial.github.io/sf/index.html  
*  and nice intro: https://oliviergimenez.github.io/intro_spatialR/#1    
*  geocomputation: https://geocompr.robinlovelace.net/spatial-operations.html 

**7. Lots of EPSG Codes for map projections**  
* Use EPSG codes as unique and specific identifies of your coordinate reference systems instead of writing projection details.  
* for EPSG codes see http://spatialreference.org/ or https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/OverviewCoordinateReferenceSystems.pdf  
 

**8. Data analysis specials:** 

*  For analysis of  plot-based biodiversity data: package `{vegan}`  
*  For analysis of telemetry data: packages `{adehabitatHR}`, `{adehabitatLT}`, `{move}`, `{recurse}`, `{momentuHMM}`, `{moveHMM}`, `{ctmm}`

## Further reading

**1. Check Roger Bivand's publications:**   
* http://cran.r-project.org/web/views/Spatial.html   
* *THE* https://r-spatial.org/book/

**2. Check Edzer Pebesma's course materials and publications:**   
* http://ifgi.uni-muenster.de/~epebe_01/  
* https://edzer.github.io/UseR2017/   

**3. Geocomputation with R: a open-access book of Robin Lovelace, Jakub Nowosad & Jannes Muenchow**  
* https://geocompr.robinlovelace.net  

**4. DataVizArt  Cedric Scherer -> check out his #TidyTuesday or #30DaysMapChallenge contributions**  
* https://www.cedricscherer.com/top/dataviz/  
* Codes: https://github.com/z3tt/TidyTuesday and https://github.com/z3tt/30DayMapChallenge  


# Basics

## How to install...

```{r package-install}
pkgs <- c("terra", "stars", "sf", "sp", "rasterVis",
          "ggplot2", "tmap", "viridis", "patchwork", "here", "units",
          "devtools", "osmdata", "elevatr","jpeg")

## install packages that are not installed yet
## (not important to understand the following code, just run it)
unavailable <- setdiff(pkgs, rownames(installed.packages()))
install.packages(unavailable)

## -------- Please run the following ---------------------
## install development version of rnaturalearth as currently the 
## download doesn't work in the CRAN package version
#devtools::install_github("ropensci/rnaturalearth")

## install rgeoboundaries from GitHub (not available on CRAN yet)
#devtools::install_github("wmgeolab/rgeoboundaries", force = TRUE)
```

## ...and load packages

```{r libraries, warning=FALSE}
## when working with spatial data
## do NOT load both packages {terra} and the old {raster} at the same time, 
## as this creates problems with the namespace!!! 
library(terra) 
library(rasterVis)

## working with vector data
library(sf) ## the "new" {sp} package
library(sp) ## the old one. Still has some nice functionalities
library(stars)

## visualization
library(ggplot2)
library(tmap)
library(viridis) ## nice colour palettes
library(patchwork) ## to combine plots

library(units) ## handle measurement data
library(here) ## for easy directory management

## depending on the sequence of installation
## you might need to reinstall this. But wait for an error message.
#install.packages("Rcpp", repos="https://rcppcore.github.io/drat")

```

## How to call help 

Remember to use '?' or '??' if you want information about a function of package. If you do not understand some of the code below, always check the arguments and help of the function. Vignettes are helpful code demonstrations with examples.

```{r helps, eval=FALSE}
## Information about a function or a package. 
?terra

## search for an item:
??SpatialPolygons

## show the instructions of a package:
vignette(package = "sf") # vignette(package="sp")

## load the instruction of a package (embedded pdf):
vignette("sf1") 

## For a better version of the sf vignettes see 
# https://r-spatial.github.io/sf/articles/
```

## Using the namespace

Important is setting the namespace. Sometimes, packages use the same
name for a function that does different things (like *plot*), so it is helpful to set the
namespace with a :: . That is, provide the library/ package from which you want to
use the function with 'package::function'.


```{r methods, eval=FALSE}
terra::plot() ## the :: provides the namespace, 
              ## i.e. that the function 'plot' is from the terra-package
```


## Set the workspace

If you have downloaded the repository for the course as described here 
(https://ecodynizw.github.io/teaching.html), you automatically have adopted our 
folder structure. Nothing more to do! Continue with chapter
'`R-projects` and package `{here}`'.





<details><summary> Click here for optional - use own course folder setup and R-project </summary>

### Optional - setting workspace by hand and learn about R-projects

If you have not downloaded the course folder structure with the R-project, you can also do it 'manually': Set your root directory <your folder name>, e.g. the directory under 
which you store everything
you need for this course, like the data and the R-Scripts, with `setwd()`. You could name it
'd6_teaching_collection'.

Create the subfolders relative to root-folder. Please adjust to your setup. 
A possible folder structure could be: 


``` bash
.
└── <your folder name>                    ─ root folder , e.g. d6_teaching_collection
    ├── data                              ─ data
    │   └── data_borneo                   ─ e.g., the Borneo data
    │       ├── geo_raster_current_asc    ─ geo data, raster ascii format, as in data_borneo
    │       └── animal_data  
    └── R                                 ─ store here all your scripts, i.e.
        ├── my_script_course1.R
        └── my_script_course2.R
```


Traditionally, the working directory was 'hard coded', i.e. the full path was specified with setting the work directory by `setwd()`.

```{r wd, eval=1}
## adjust the working directory [wd]
getwd()  ## check where you are

## Set your OWN root directory, the following is just an example of how to do it:
#root_wd <- setwd("C:/Users/kramer/d6_teaching_collection")
```


This approach is error-prone and it complicates the cooperation with others as 
they have to update the working directory in every script they receive from you. 
(And if they don't change it back to your directory, you also have to update it again...)

Nowadays, the best approach is to work with [R projects](https://support.rstudio.com/hc/en-us/articles/200526207-Using-RStudio-Projects) 
that are associated with own working directory, workspace, history, and source documents. 

You can create a project in the RStudio IDE by using the `Create Project` command 
(available on the Projects menu and on the global toolbar). In our case, we want 
to create a project in an existing directory where there is already R code and 
data placed inside that given folder. Now, a hidden folder called `.Rproj.user` and 
most importantly a file called `your_project.Rproj` should appear in your folder. 
Every time you want to work on your project, you open the Rstudio session by 
double-clicking on that `.Rproj` file, which ensures that the root working directory 
is correctly set.

End of optional.

</details>



### `R-projects` and package `{here}`

When using R projects, the package `{here}` is a handy helper: 

![Illustration here package by Allison Horst](https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/rstats-artwork/here.png)

The goal of the `{here}` package is to enable easy file referencing in project-oriented workflows. In contrast to using `setwd()`, which is fragile and dependent on the way you organize your files (see optional section above for details), `{here}` uses the top-level (=root) directory of an `R-project` to easily build paths to files.

The `here()` function from the `{here}` package searches for the `.Rproj` file and 
will allow you to construct relative paths easily within your project environment:

```{r here}

# tip: use the namespace here:: before calling to function here()
# because here() alone interferes with the package `purrr` if that is loaded
here::here()    
here::dr_here()

# this is an example, ob how a long folder path can be assigned to a short name (root_wd)
root_wd <- here::here() # the root folder is automatically set
root_wd        
```

Now, we assign the path to these folders that contain our data
relative to the root directory, and
we work with the Borneo data:


``` bash
.
└── root_wd                    ─ e.g. d6_teaching_collection 
    └── dbor_wd                ─      data / data_borneo
        ├── maps_wd            ─      geo data
        └── anim_wd            ─      animal location data
```

```{r dirs}
## Now, create the linkages to the folders:

# dbor_wd     <- paste0(root_wd, "/", "data/data_borneo") #- the old way
dbor_wd     <- here("data","data_borneo") #- note the nested folder structure

# maps_wd   <- here("data","data_borneo","geo_raster_current_asc")  ##  same as:
maps_wd   <- paste0(dbor_wd, "/geo_raster_current_asc") 
             
# mind difference paste0() and paste() :
# paste() needs a separator sign, in this case no space ''
vecs_wd   <- paste0(dbor_wd, "/geo_vector")
anim_wd   <- paste(dbor_wd, "/animal_data", sep = '')   
```


Create an output folder where you can temporarily store your results (anything
you plot, create, want to save,....) with *dir.create*. If you use our downloaded
course repository, you already have this folder.

```{r output-wd}
output_wd <- here("output") # assign the path name
output_wd ## check
if (!dir.exists(output_wd)) dir.create(output_wd) # create only if directory does NOT! exist
```

Finally, your folder structure will look like this:

``` bash
.
└── <your folder name>               ─ root folder , e.g. d6_teaching_collection
    ├── data                         ─ data
    │   ├── data_borneo              ─ e.g., the Borneo data
    │   ├── geo_raster_current_asc   ─ geo data, raster ascii format, as in data_borneo
    │   └── animal_data  
    ├── R                            ─ store here all your scripts, i.e.
    │   ├── my_script_course1.R
    │   └── my_script_course2.R
    ├── output                       ─ for any results/ plots,...
    └ <your R project name.Rproj>    ─ in case you are working with an R-Project
```


A small yet important hint on file and folder naming: Do NOT! use dots (NOT: folder.name),
spaces, comma, semicolon, or any special signs like ö, ä, ü, ß, ! etc. in your folder names, 
and keep name length at a maximum of 13 letters!


## Access folder content

You will find a lot of bioclimatic raster files (.asc) in the
*geo_raster_current_asc* folder, which we named `maps_wd` above:

```{r filenames}
## create an object called 'filename' and store the names of the files
filenames <- list.files(path = maps_wd)

## show the first six files
head(x = filenames)

## if you want to see all stored files, use
# filenames
```
Should this directory be empty, then you have wrongly set the root directory and the data directory. Please check again how your folder structure looks like. By default, this folder should contain six ascii-files. The description what info these maps contain is provided in the *DataDescription_Borneo.doc* in the 
*data_borneo* folder that you downloaded with the repository.


## Recap from Course 1 Basics in R

**useful functions:**

-  `head()`: only shows the first 6 elements, i.e. if you have a large data frame, you can quickly check header and the first entries (analogously: `tail()`)
-  `paste(x, sep='')`: appends characters or numbers — great for working directories, loops across many maps or data.frames etc
  
  
**data formats and access:**

-  `data.frame()`:  [row, column] or "dollar sign", i.e. `mydata[1,2]` &rarr; first row, second column, or `mydata$MyColumnName[1]`
-  `matrix()`:  see above
-  `list()`:  [[element]], i.e. `mylist[[1]]`. Attention! A list element can consist of a data.frame that you can then access like that: `mylist[[1]][1,2]`...
  
  
*S4-objects* (like spatial data)

-  access via `@`, i.e. `SpatRaster@data@values`



#  Raster data

## Data import 

First, load a raster map. Please check the description in the folder called
*DataDescription_Borneo.doc*. The file *bio_asc_01.asc* is showing mean annual 
temperature multiplied by 10. Why?  Because it can be stored as integer, 
not floating type (i.e. with digits), which saves a lot of storage and memory.

```{r read-raster, eval=-1}
## read the ascii file as raster format
ras_bio_asc_01 <- terra::rast(x = paste0(maps_wd, "/bio_asc_01.asc")) 

## or use function 'here' (which in this case is much longer.....)
# ras_bio_asc_01 <- terra::rast(x = here("data", "data_borneo","geo_raster_current_asc", "bio_asc_01.asc"))

## copy the raster map and give it a sensible name
Bor_mat <- ras_bio_asc_01  ## easy copying of whole maps; mat stands for mean annual temp
```

Now have a look at the object:

```{r inspect-raster}
Bor_mat
```

What does the slot with *extent* tells you? Looks like coordinates in decimal degrees, i.e.  latitude and longitude. 

  Now have a look at the slot `coord. ref.` (or `crs`. CRS stands for **c**oordinate **r**eference **s**ystem): Nicely in the new `{terra}`-package, the CRS (map projection) is automatically set in the following way: If the `crs` argument is missing when loading data with `rast(x= ..., crs= ...)`, and the x coordinate values are within -360 .. 360 and the y coordinate values are within -90 .. 90, **automatically** "+proj=longlat +datum=WGS84" is assigned. WGS84 is the global reference system for geospatial information and is the reference system for the Global Positioning System (GPS). In this case, (OGC:CRS84) stands for 'Open Geospatial Consortium' OGC standards to represent the coordinate reference system WGS84. The parameters for this CRS are now stored in so-called 'well-known text' (WKT) files. We will come back to that later. 

However, sometimes the slot `coord. ref.` is empty, i.e. if other coordinates than decimal degrees are used, e.g. UTM. That means, without knowing the reference system, the map cannot be plotted at the exact location on the globe. Thus, when you get a map, always
make sure you also get the information of the coordinate reference system! If it 
is not yet set/ assigned (because you import a raster map as a simple matrix or points from
a file), this is the first thing you should do!

```{r}
# str(Bor_mat) ## check this
crs(Bor_mat)   ## crs = coordinate reference system. If empty, assign it!
```

In this case, it was automatically assigned, so nothing to do for now.

## Assign the CRS

*Important!* Please read and repeat basic GIS-knowledge on coordinate reference 
systems (CRS), map projections, and geographic and projected coordinates. This issue is also covered in the lecture prior to this course for TUB students.  

If a map already has a defined CRS, then you cannot simply overwrite this! To
re-calculate the coordinates from one system into another system (e.g. from 
angular coordinates of latitude/ longitude of WGS84 
to a projected CRS with planar coordinates and meter distances, equal area of 
Lambert Azimuthal),
you need to *transform* it with the function  `project()`(raster-data) or
`st_transform()`(vector-data) (see chapters below).


In the following, we assign the CRS only when no information is provided. This can be 
the case when you upload a map based on a simple `data.frame` or `matrix`, i.e. when
it is not yet a spatial object. 
  
`crs(<raster>)` gives the information of the object (here: raster layer) `Bor_mat` or `ras_bio_asc_01`, and is also used to set the CRS of the object via assignment: `crs(<raster>) <- <projection>`.  

* `crs(<raster>)` shows coordinate reference system of a spatial object
* `crs(<raster>) <- <projection>` creates projection and sets arguments for CRS!

An easy way to specify the CRS is using a unique identifier system, where all parameters of the projections are stored. A well-known identifier (WKID) is the EPSG code. E.g. instead of `"+proj=longlat +datum=WGS84"` use `"+init=epsg:4326"`.

See http://spatialreference.org/. The EPSG code for WGS84 is 4326.


In case the CRS was not yet assigned:
```{r change-crs}
# many ways to assign the CRS, options listed below:
crs(ras_bio_asc_01) <- "+proj=longlat +datum=WGS84" 
crs(ras_bio_asc_01) <- "+init=epsg:4326"
```

Projections can also be transferred from one object to another, 
but only when the CRS hasn't yet been specified and the coordinates are
stemming from the same system, i.e. longitude/ latitude.  
  
In the following, load the topographic map (digital elevation model) of 
Borneo (`Bor_dem.asc` or `bio_asc_24.asc`) and assign it the same CRS as `Bor_mat`, 
because we know they are overlaying (you can check that with the raster extents):

```{r new-raster-import}
## ras_bio_asc_24 = DEM = digital elevation model
ras_bio_asc_24 <- rast(x = paste0(maps_wd, "/bio_asc_24.asc"))  

crs(ras_bio_asc_24)

## if not assigned, it could also be copied:
# crs(ras_bio_asc_24) <- crs(ras_bio_asc_01) 
## same as: 
# crs(ras_bio_asc_24) <- crs("+proj=longlat +datum=WGS84")
```


Quickly visualize the data with the easy base plot:

```{r ras-base-plot}
## base plot
plot(x = ras_bio_asc_01)
```

(More plotting later!)

## Clip areas

We do this first to work with a small raster to save computation time. For this, 
we create a clip_extent based on the spatial coordinates. The command/ function `crop()` then 
clips the raster map.

```{r, fig.height=5}
ext(x = ras_bio_asc_01) ## get the extent
clip_extent <- ext(117.2, 117.45, 5.4, 5.5) ## create a subset based on long/ lat coordinates
ras_bio_asc_01_cr <- crop(x = ras_bio_asc_01, y = clip_extent)

plot(ras_bio_asc_01_cr, col = viridis::inferno(10))
```


## Accessing *SpatRaster* objects

First, have a look at the internal data structure
of the raster object:

```{r ras-data-structure}
ras_bio_asc_01_cr

## get additional information:
# str(ras_bio_asc_01_cr) ## strucutre of object
# attributes(ras_bio_asc_01_cr) ## available slots
# class(ras_bio_asc_01_cr) ## object type in R
```


There are many ways to retrieve internal data and access single bits of 
information:

```{r ras-data-structure-2}
## spatial extent
ext(ras_bio_asc_01_cr)

xmin(ras_bio_asc_01_cr) ## or: xmin(ext(ras_bio_asc_01_cr))
ncol(ras_bio_asc_01_cr)
head(ras_bio_asc_01_cr)
crs(ras_bio_asc_01_cr) ## != CRS(ras_bio_asc_01_cr) ## mind the spelling

## crs = coordinate reference system defined
## CRS creates projection and takes args for crs!
## e.g. 
wgs84_crs_args <- CRS("+proj=longlat +datum=WGS84")
wgs84_crs_args  ## please check! You will see the WKT representation of the parameters
```

```{r ras-data-structure-3}
## Retrieve internal data cont.:
nrow(x = ras_bio_asc_01_cr) # ncell(ras_bio_asc_01_cr)
dim(x = ras_bio_asc_01_cr)  ## 12 rows, 30 columns, 1 z-dimension
res(x = ras_bio_asc_01_cr)  ## resolution = cell size
```
Any idea what this kind of strange cell size could be? We will come to that later.


An important function is `crds()`, which returns the centroids of each raster cell:
```{r centroid}
head(x = crds(ras_bio_asc_01_cr), n = 10) 
```


## Terrain computation

We will now work with the digital elevation model (DEM) `ras_bio_asc_24` and create
a hillshade (3D look) based on topography using slope and aspect:
- simulates a 3D surface
- computes shaded relief values for a raster surface

```{r calculate-slope-aspect}
slope <- terrain(x = ras_bio_asc_24, v = "slope", unit = "radians", neighbors = 8) 
aspect <- terrain(x = ras_bio_asc_24, v = "aspect", unit = "radians", neighbors = 8) 
Bor_hs <- shade(slope, aspect, angle = 45, direction = 270) 

```


Let's plot the hillshade:

```{r plot-hillshade}
plot(Bor_hs, col = grey(0:100/100), legend = FALSE)
```


Other very useful terrain calculations are cost surfaces, cost distances
and least cost path, e.g. for corridor calculations. We will do that in
another course.


## Visualising rasters 

Above we used the basic `plot()` function, but there are pretty alternatives available.

### Easy to use: the `{tmap}` package 

#### Static map

```{r ras-tmap-static}
tmap_mode(mode = "plot")
tm_shape(shp = ras_bio_asc_01) + tm_raster()
```


If you want to use a static map as high quality plots for your publication, 
save the output via `tmap_save()`.
```{r tmap-save-static-map}
tmap_mode("plot")

(m <- tm_shape(ras_bio_asc_01) +
  tm_raster(palette = "viridis",  title = "Mean annual temp"))
```

Make sure that the quality is sufficient by 
setting the dpi ("dots per inch") to at least 600. We save this map in our output folder.

```{r tmap-save-static-map2}
tmap_save(m, paste0(output_wd, "/BorneoMap_4326_tmap.png"), 
          units = "mm", width = 90, height = 90, dpi = 600)
```

The saved map: check output folder

```{r tmap-saved-plot, echo=FALSE}
#knitr::include_graphics("./output/BorneoMap_4326_tmap.png")
```


#### Interactive map  

Very good for checking the correct location of the data. Great for zooming in/ out or overlaying with open street map data:
```{r ras-tmap-interactive}
tmap_mode(mode = "view")
tm_shape(shp = ras_bio_asc_01) + tm_raster(alpha=0.5)
```

Click on the + | - | layer 
icons on the upper left and zoom in or out and change the background layers by clicking on the layer icon. The
'alpha' argument makes the layer transparent. 

If you like, you can save the interactive map — check your output folder for the html 
file. 

Tip of the day: always save the epsg code of your crs at the end of
a spatial file name.

```{r tmap-save-interactive-map}
tmap_mode("view")

(i.m <- tm_shape(ras_bio_asc_01) +
  tm_raster(palette = "viridis",  title = "Mean annual temp"))

tmap_save(i.m, paste0(output_wd,"/BorneoMAT_4326.html"))
## or use here: 
# tmap_save(i.m, here("output","BorneoMAT_4326.html"))
```

<details><summary> Optional - Visualising rasters with the `{ggplot2}` package </summary>

### Visualising rasters with the `{ggplot2}` package

For advanced R-users familiar with `ggplot()` coding style: Beautiful plots can also be made with `{ggplot2}`; 
however, `SpatRaster` objects cannot directly be plotted. One can use the [`{stars}` package](https://r-spatial.github.io/stars/). 

The [`{stars}` package](https://r-spatial.github.io/stars/) is another package 
aimed at working with spatial data, namely spatio-temporal arrays (such as raster 
and vector data cubes). We first turn our raster into a `stars` object using
function `st_as_stars` and can 
then use the `geom_stars()` function in combination with `ggplot`:

```{r ras-ggplot-stars}
stars_bio_asc_01 <- st_as_stars(ras_bio_asc_01)
class(stars_bio_asc_01)

g <- ggplot() +
  geom_stars(data = stars_bio_asc_01) +
  scale_fill_viridis_c(name = "°C * 10", na.value = "transparent") + 
  coord_sf(crs = "+init=epsg:4326") + ## set correct projection 
  labs(x = "Longitude", y = "Latitude",
       title = "Mean annual temperature") +
  theme_minimal() ## set custom plot style

g
```


The nice thing about ggplot is the flexibility to customize your plot further. 
Thus it is very suitable to create static high-quality maps for publication 
which can be saved via `ggsave()`. Make sure that the quality is sufficient by 
setting the dpi ("dots per inch") to at least 600.

```{r ggplot-save}
g2 <- g + theme(plot.title = element_text(size = 18, face = "bold"),
                plot.title.position = "plot",
                legend.position = c(0.2, 0.95),
                legend.direction = "horizontal",
                legend.key.width = unit(2.2, "lines"),
                legend.key.height = unit(0.7, "lines"))
g2

ggsave(filename = paste0(output_wd, "/BorneoMap_4326_ggplot.png"),
       width = 8, height = 7, dpi = 600, bg = "white")
```

(`ggsave()` saves automatically the last ggplot. You can also specify a ggplot object via `plot = `).

The saved map: check output folder

```{r ggplot-saved-plot, echo=FALSE}
#knitr::include_graphics("./output/BorneoMap_4326_ggplot.png")
```

Further beautiful ideas with ggplot:
https://eliocamp.github.io/metR/reference/geom_contour_tanaka.html

End of optional plotting.

</details>


### 3D plot with `persp()`

```{r 3d-plot}
# Cool 3D plots with rgl library, e.g. 'rgl.surface'
persp(x = ras_bio_asc_24, xlab = "Easting", ylab = "Northing",
      zlab = "elevation", r = 9, d = 1.5, expand = 0.1,
      ticktype = "detailed")
```



Why is the map so spiny? Check units of x, y and z coordinates! This is still a geographic CRS, not a
projected one. The units are in degrees. Solution: project! (chapter: Raster projection).


## Raster projection

Project the grid (the small one!! because for large rasters it may take a long time) to have all units in meters. Remember from basics in GIS: We are now changing from angular units for the x and y coordinate (long/ lat) to a CRS where the x and y coordinates are given in meter units.

```{r unit-meter}
Bor_dem_moll <- terra::project(ras_bio_asc_01_cr, "+proj=moll +lat_0=65 +lon_0=10") 

persp(Bor_dem_moll, xlab = "Easting", ylab = "Northing",
      zlab = "elevation", main = "Elevation model of Borneo",
      r = 1, d = 5.5, expand = 0.1, ticktype = "detailed")
```


You can now try all kinds of funny projections on your own, for example, use the Albers Equal Area projection with EPSG code 3085. Give it a try:

```{r}
Bor_dem_AEA <- terra::project(ras_bio_asc_01_cr, 'EPSG:3085') 

persp(Bor_dem_AEA, xlab = "Easting", ylab = "Northing",
      zlab = "elevation", main = "Elevation model of Borneo",
      r = 1, d = 5.5, expand = 0.1)
```



## Raster Stacks

A raster stack is a collection of `SpatRaster` objects
with the same spatial extent and resolution, similar to a geo-database. 
Go into the maps folder and check what is inside:

```{r raster-stacks-dir}
## gives names and full path of file
files.full <- list.files(path = maps_wd, pattern = '.asc$', full.names = TRUE)
# files.full ## check also 
files.full[1:3]

## names only
files.rel <- list.files(path = maps_wd, pattern = '.asc$', full.names = FALSE)
files.rel[1:3]
```

Tip of the day: Always work with the full path, as you might have stored interim results of maps with the same name in other folders than your target folder. You can avoid using the wrong maps by using the full path specification to the respective data files.

The advantage is that you do not need to apply a command to each raster map 
separately, but can do it 'all in one'. E.g., We can set the crs of each 
single raster in just one line. In the following, we *stack* four maps in
a 'geodatabase' called 'predictors'. In the following, we select 4 spatial layers, numbers 1, 12, 22 and 24.
The description of what they represent is in the data description .doc in the map folder. 
We load them all together with `terra::rast()`

```{r predictor-stack}
predictors <- rast(x = files.full[c(1, 2, 4, 6)]) 
crs(predictors) #ask whether/ in which CRS the coordinates are in
## it is already assigned. If not:
#crs(predictors) <- "+proj=longlat +datum=WGS84" #or# ... <- "EPSG:4326"
```


A raster stack contains the single raster layers in a list:

```{r stack-list}
predictors ## this is a list! Address single layers with [[ ]]
predictors[[1]] ## now you address the first layer
## with {terra} you can also use $ syntax:
predictors$bio_asc_01
```


### Plotting stacks 

Plotting just one layer:

```{r plot-stack-one-layer}
plot(predictors$bio_asc_42) ## = plot(predictors[[4]])
```

Plotting all layers:

```{r plot-full-stack-base}
plot(x = predictors)
```


Hint: With `{tmap}`, plotting all stack layers at once is not recommended: 
`{tmap}` is standardizing the legend to the min and max of all layers, which is 
problematic if maps are not in the same units. That's why you cannot see the
information in the maps:

```{r plot-full-stack-tmap}
tmap_mode(mode = "plot")
tm_shape(shp = predictors) + tm_raster()
```



## Manipulating rasters

Do any kind of raster algebra (summing, dividing,...) with the raster. Important: if you are adding the values of two `SpatRaster` objects, the projection and extent must be the same.

```{r manipulate-raster-calc}
new_ras <- ras_bio_asc_01 + ras_bio_asc_24 + 100
```


For changing cell size use aggregate() or resample():

```{r manipulate-raster-aggrgeate}
## collapse 20*20 cells into 1 using function (fun) 'mean':
ras_bio_asc_01_agg <- aggregate(x = ras_bio_asc_01, fact = 20, fun = mean) 
```


We finally plot the two new rasters next to each other:

```{r plot-manipulated-rasters}
par(mfrow = c(1,2)) # recap from course 1: plots in 1 row and 2 columns
plot(x = new_ras, col = rev(rainbow(5)))
plot(ras_bio_asc_01_agg)
par(mfrow = c(1,1)) # remember to set it back to the default
```



### Queries on raster values

You can easily access the cell information of the raster via `values()`

```{r change-raster-values}
## convert ras_bio_asc_01 to degree Celsius units (divide by 10)
range(values(ras_bio_asc_01), na.rm = TRUE)
```

Visualise range of the values with a simple boxplot (see course 1 R Intro).

```{r raster-boxplot}
boxplot(values(ras_bio_asc_01), na.rm = TRUE, outline = FALSE) ## outline = outliers
```

Similarly, we can look at the distribution of the values in each single layer of a raster stack.

```{r}
boxplot(predictors, outline = FALSE)
```


Example: Find areas with mean annual temp above 25 degrees Celsius

```{r change-raster-values-binary-query}
## first divide by 10 to get 'realistic' temperature ranges. Remember the values
## of the raster had integer values because this data type uses less computer memory
## than a floating-point number (meaning numbers with digits)

mean.t.c <- ras_bio_asc_01 / 10
range(values(mean.t.c), na.rm = TRUE)

## now ask which ones are above 25 degrees Celsius
mean.t.c.25 <- mean.t.c >= 25
mean.t.c.25 ## check the values -> binary! 
```

Have a look at the result using a binary plot, i.e.all areas where the temperature is above 25 degrees (TRUE) are plotted:

```{r binary-plot}
plot(x = mean.t.c.25)
```


Retrieve metrics/ statistics from the `SpatRaster` objects with function `global()`:

```{r metrics-raster}
round(x = global(x = predictors, stat = 'mean', na.rm = TRUE), digits = 2) 
```


<details><summary> Optional - pretty violin plots in ggplot2 </summary>

With the help of the `{rasVis}` package we can plot violin charts `bwplot()` to visualize the summary statistics of a raster across all raster cells:

```{r violin-plot-predictors}
rasterVis::bwplot(x = predictors[[c(1, 3)]]) 
## n.b. double [[ ]] because stack is a list of spatial rasters
```

However, these plots are not really pretty. 
More beautiful violin plots can be found in ggplot2. 
For this, we need to transform the `SpatRaster` data
into a data.frame first:

```{r violin-ggplot-prep}
## first omit NA values (which represent the ocean around Borneo)
raster_df <- na.omit(data.frame(values(predictors[[c(1,3)]])))

raster_names <- names(raster_df)
raster_ct    <- dim(raster_df)[1]
df2 <- data.frame(val = c(raster_df[,names(raster_df)[1]], 
                          raster_df[,names(raster_df)[2]]))
df2$grp <- rep(raster_names , each = raster_ct)
head(df2)

## take a random subsample of the data to not crash your PC when plotting:
a <- sample(x = nrow(df2), size = 1000, replace = FALSE) 
df3 <- df2[a,]
```

```{r violin-ggplot}
## a violin-box plot combination with raw data strips
p <- ggplot(data = df3, aes(x = grp, y = val)) +
  geom_violin(scale = "width", fill = "grey85", color = "#3366FF", bw = 20) + 
  geom_boxplot(width = 0.15, size = 0.8, outlier.color = NA) + ## remove outliers 
  geom_jitter(height = 0, width = 0.05, alpha = 0.2, size = 1.5, color = 'blue')

p
```


Since the units are so different, it makes more sense in this case 
to plot them separately, using a `facet_wrap()` and `scales = free`.

```{r violin-ggplot-facet}
p +
  facet_wrap(vars(grp), scales = "free") +
  scale_x_discrete(guide = "none")  + ## remove axis ticks and labels on x
  labs(x = NULL, y = "Value") +
  theme_minimal(base_size = 15) ## set custom plot style
 
# save the last plot
ggsave(paste0(output_wd, "/savedggplot.pdf"), width = 5, height = 5, dpi = 600)
## or use here:
# ggsave(here("output", "savedggplot.pdf"), width = 5, height = 5, dpi = 600)
```


...or plot them separately and combine them using the [`{patchwork}` package](https://patchwork.data-imaginist.com/):

```{r violin-ggplot-patchwork}
df3_bio1 <- subset(df3, df3$grp == 'bio_asc_01')
df3_bio24 <- subset(df3, df3$grp == 'bio_asc_24')

p1 <- ggplot(data = df3_bio1, aes(x = grp, y = val)) +
      geom_violin(scale = "width", fill = "grey85", colour = "#3366FF") + 
      geom_boxplot(width = 0.2, size = 0.8, outlier.color = NA) + ## remove outliers 
      geom_jitter(height = 0, width = 0.05, alpha = 0.2, size = 1.5, colour = "#3366FF") +
      labs(x = NULL, y = "Value")

p2 <- ggplot(data = df3_bio24, aes(x = grp, y = val)) +
      geom_violin(scale = "width", fill = "grey85", colour = "#3366FF") + 
      geom_boxplot(width = 0.2, size = 0.8, outlier.color = NA) + ## remove outliers 
      geom_jitter(height = 0, width = 0.05, alpha = 0.2, size = 1.5, colour = "#3366FF") +
      labs(x = NULL, y = "")

p1
p2
## multipanel plot with {patchwork}
(p1 + p2) * theme_minimal(base_size = 15) ## apply custom style
```


check here for how `{ggplot2}` works if you want to make really nice plots:
* https://github.com/rstudio/cheatsheets/blob/master/data-visualization-2.1.pdf


or get inspiration here:

* https://www.cedricscherer.com/2019/08/05/a-ggplot2-tutorial-for-beautiful-plotting-in-r/
*https://www.r-graph-gallery.com/

Back to spatial R!

</details>



### Accessing and changing single raster cell values

Remember the function **`extract()`**. In the following, we extract from the
small raster the first three values (= cols 1-3; longitude or x-axis) 
at line 5 (= row 5; latitude or y-axis).

```{r accessing-raster-values}
cells <- cellFromRowCol(object = ras_bio_asc_01_cr, row = 5, col = 1:3)
cells    ## Note: returns cell ID number = the index / row number! Not the value!!!!

## returns cell values!: 
extract(x = ras_bio_asc_01_cr, y = cells) 

## plot it:
plot(x = ras_bio_asc_01_cr)
## to plot the points on top, insert the 'cells' index into 
## the data frame of the coordinates (crds) of the SpatRaster object ras_bio_asc_01_cr.
## Do you fully understand the following line?:
points(x = crds(ras_bio_asc_01_cr)[cells,], col = "blue")
```

Change raster values in an existing raster:

```{r change-raster-values-again}
## get the coordinates; cells was the object containing the index (i.e. the cell numbering)
## the function returns a matrix (it could have been easy...)
xy <- xyFromCell(object = ras_bio_asc_01_cr, cell = cells) 
xy
class(xy)

extract(x = ras_bio_asc_01_cr, y = xy) ## direct access to the cell values, not the index         

## Change values of a raster, e.g. for adding forest or creating a corridor
## take care! -> irreversible! better work on a copy!
copy_ras <- ras_bio_asc_01_cr
copy_ras[cells] <- 250 # here we set all values in the raster at the position index cells to 250
plot(x = copy_ras, col = viridis(20))
```



<details><summary> Optional - extract values from a stack </summary>
   
Advantage of working with stacks: Extract raster values 
from all `SpatRaster` objects at once (raster stack).
This is very important if you want to create your master table, i.e. based 
on the xy-coordinates of your species sightings (i.e. GPS point locations), 
you could extract the underlying values of all  environmental predictors 
at that location in one go. 


We do that for an area in the center of Borneo. For this, first get the
row and column indices of the center of a large Borneo map, e.g. `ras_bio_asc_01`, and
5 x 5 cells in addition, i.e. a square with an area of 5 km x 5 km:

```{r extract-raster-values}
## divide by 2 to get the center cell
center_x = floor(nrow(predictors) / 2) ## learn about the functions round(), 
center_y = floor(ncol(predictors) / 2) ##                 ceiling(), floor()
center_x; center_y ## center coordinates of the Borneo maps

## start from center cell and go 5 cells in x and y direction
## This should yeald 25 cells
stack_cells <- terra::cellFromRowColCombine(
  object = ras_bio_asc_01, 
  row = c(center_x:(center_x + 4)), 
  col = c(center_y:(center_y + 4))
)

## check 
#?cellFromRowColCombine
## to get an overview over all possible functions to get acces to the raster

head(stack_cells) ## mind: these are index numbers! Not cell values!
```


Why are these index numbers so large? Because the counting
starts at the upper left corner of the map and continues consecutively, i.e.
the data (`ras_bio_asc_01@data@values`) are one huge vector with length `nrow * ncol`!


Now, extract them with the useful function `èxtract()` into an object called 'mastertable' that you can for example use for statistical analyses in R:

```{r extract-raster-values-finally}
pred_dat <- extract(predictors, stack_cells) 
head(pred_dat)

## combine in one table
mastertable <- data.frame(stack_cells, pred_dat)
head(mastertable)
```

End optional.

</details>


### Compute distance to points

From the three selected cells in the small raster 'ras_bio_asc_01_cr', we want to
calculate the distance to each other cell in the raster.

```{r create-spat-vect}
## remember from above: the object 'xy' was a matrix ## check #class(xy)
## turn first into SpatVector - this is the format needed for the distance() function below
## we do this just for 1 cell (point),
sv_xy <- vect(xy)[1] 
sv_xy
```

Check the object `sv_xy`: since `xy` was a simple matrix and not a spatial object, there is no crs assigned. The slot for 'coord.ref.' is empty. That means, we now have to first assign
the CRS so that the following functions know where exactly the different layers are on earth.

```{r}
crs(sv_xy) <- "epsg:4326"

## check: 
sv_xy

## Nice!
```

Now the CRS is set/ assigned and we can continue with distance calculations:

```{r compute-distance}
## calculate distance
my_dist <- distance(x = ras_bio_asc_01_cr, y = sv_xy)
plot(x = my_dist) ## units?
points(sv_xy)
```


Calculate distance from many points:

```{r compute-distance-multiple}
cells1 <- c(cells, 250, 360) ## add  more randomly chosen points to cells = cells1
sv_xy_2 <- vect(xyFromCell(ras_bio_asc_01_cr, cells1)) ## we create a new spatVect
crs(sv_xy_2) <- "epsg:4326" ## same procedure as above
my_dist <- distance(x = ras_bio_asc_01_cr, y = sv_xy_2)

# viz
plot(my_dist) #units?
points(sv_xy_2) #
```


## Data export - saving raster data

Save the raster (not the plot...): There are many exchange formats for rasters. 
The best choice is considered to be GeoTiff, which also saves the projection and is smaller than 
ascii. However, for modelling e.g. in MaxEnt, the raster maps are needed in ascii-format. Also,
ascii type files can be opened easily in any text editor. Try this with the small cropped raster.

```{r save-raster}

## save the small cropped file
terra::writeRaster(x = ras_bio_asc_01_cr, 
            filename = paste0(output_wd,"/bor_crop.asc"), 
            # or use here(): here("output", "bor_crop.asc")
            overwrite = TRUE, 
            NAflag = -9999)


terra::writeRaster(x = ras_bio_asc_01_agg, 
            filename = paste0(output_wd,"/ras_bio_asc_01_agg.asc"), 
            # or use here(): here("output", "ras_bio_asc_01_agg.asc")
            overwrite = TRUE, 
            NAflag = -9999)
```




# Vector data / shapefiles

## Import shapefiles

Currently, there are two packages *sp* and *sf* (standing for simple features),
both with still important functionality. However, sf is much easier to use and handle. 
The suggestion currently is: [learn both!](https://www.r-bloggers.com/2018/03/should-i-learn-sf-or-sp-for-spatial-r-programming/)

In the following, the most important commands are provided for the sf-package,
and if necessary, also for the sp-package. We start with loading an ESRI shapefile.

```{r sf-versus-sp}
## Border of countries and provinces of Borneo
## vecs_wd is the folder where vector data are stored
## - only loading columns 1:3, 5, 7, 17, 18 of its attribute table (a. t.):
Borneo_shp <- st_read(dsn = vecs_wd, layer = "borneo_admin")[, c(1:3, 5, 7, 17, 18)] 

## Protected Areas (National Parks, Nature Reserves, Forest Reserves)
PA_shp     <-  st_read(dsn = vecs_wd,
                       layer = "Bor_PA")[, c(1:4)]

## fix problematic polygons
PA_shp <- st_make_valid(PA_shp)

## main rivers
River_shp  <- st_read(dsn = vecs_wd, layer = "sn_100000")

## admin areas
Admin_shp <- st_read(dsn = vecs_wd, layer = "borneo_admin")[,c(1:3,5,7,17,18)]
```

More here:
- https://cran.r-project.org/web/packages/sf/vignettes/sf1.html

#### Transformations between simple feature `{sf}` and SpatialPolygonsDataFrame `{sp}`

Since some functions are still only available in the `{sp}` package, it can be helpful to remember how to back and forth-transform between the data types.
```{r sf-versus-sp2}
## transformations
Admin_sp <- as(Admin_shp, "Spatial") ## from sf to sp object
Admin_sf <- as(Admin_sp, "sf")       ## from sp object to sf object 
```


## Import spatial points

In the following, we load two point datasets of different species locations.

```{r check-projection}
pt_shp <- st_read(dsn = paste0(anim_wd, "/FCsim.shp"))
pt_shp  ## CRS is missing!
st_crs(pt_shp) <- 4326 ## set it with command st_crs()
pt_shp
```

Spatial points are defined by two columns with x and y coordinates; they can be 
imported as normal `data.frames` and then converted to spatial objects: 

```{r convert-df-to-spatial}
pt_file <- paste0(anim_wd, "/MyNewSpecies.csv")
df_recs <- read.table(file = pt_file, header = TRUE, sep = ',') # animal records
class(x = df_recs)
head(x = df_recs)
```

This is still a `data.frame`, not yet a spatial object. See below of how to convert a data.frame into a spatial `{sf}` object. You need to give the columns of your file that contain the x and y coordinates, and you need to set the CRS.

```{r convert-df-to-sf}
recs_sf <- st_as_sf(x = data.frame(df_recs),
                    coords = c("long", "lat"),
                    crs = 4326,
                    sf_column_name = "geometry")
```


## Working with vector data

Explore the objects and retrievable information:

```{r}
str(object = PA_shp) ## shows which slot can be addressed with $
attributes(x = PA_shp) ## similar to above
```


Accessing simple feature objects — easy handling, similar to `data.frames`:

```{r accessing-simple-features}
## Please note the similarity to accessing info from rasters.
ext(PA_shp) ## extent
xmin(ext(PA_shp))
names(x = PA_shp) ## returns column names of a.t.
```


Summarizing spatial information for each column of attribute table [a.t.]:

```{r summarize-spatial-data}
summary(object = PA_shp)
```


Have a look at the content of the attribute table. It looks like a `data.frame`, but has
the geometry stored as last column (recap from the introductory lecture).

```{r inspect-summary-table}
head(x = PA_shp)  ## first 6 lines
#tail(x = PA_shp) ## last 6 lines
```

Retrieving information of a.t. — recap working with `data.frames` 
from `Day1_R-Intro` course.

```{r retrieve-information-summary-table-1}
PA_shp[1, ] ## returns first entry (row) of all 4 columns
```

```{r retrieve-information-summary-table-2}
PA_shp[, 2] ## returns content of column 2 only!
```

```{r retrieve-information-summary-table-3}
## PA_shp$NAME_ENG ## returns a long list  
head(x = PA_shp$NAME_ENG) 
## using head() to only show the first 6 entries only of column 'NAME_ENG'
```

```{r retrieve-information-summary-table-4}
PA_shp[1, 1] ## = PA_shp$SITE_ID[1]
PA_shp[2, 3] ## = PA_shp$COUNTRY[2]
```


The following returns the row indices of the data frame or a.t., respectively:

```{r retrieve-information-summary-table-5}
which(x = PA_shp$COUNTRY == 'Malaysia')
```


## Visualising vector data

#### `plot()`

It is ok to use a simple `plot()` function for `{sf}` objects. However, 
mind that this object has 7 columns, so each column holds information that will 
be plotted, i.e. you will plot 7 single plots. So do a little transformation:
either plot just one column, or define it as `{sp}` object:

```{r base-plot-sf-1, fig.height=7}
# plot(Borneo_shp) ## not run!
plot(Borneo_shp[,1]) ## select column
```


Plotting `{sp}` objects:

```{r base-plot-sf-2}
## Defining it as(..., "Spatial"), i.e. transforming it to a `{sp}` object (see above)
plot(as(Borneo_shp, "Spatial")) ## plot geometry without information of a col
```

```{r base-plot-sp, fig.height=9}
plot(Admin_sp) ## ending _sp shows it as an `{sp}` object
```

Points in `data.frames` can be plotted, as long as the coordinates are the same, 
can also be plotted in space. We first plot the polygon, then add the points (note, one is a simple `data.frame`, the other is a shapefile):

```{r plot-sf-points, fig.height=9}
plot(x = as(Borneo_shp, "Spatial"), col = 'grey', border = 'white') ## polygon
points(x = df_recs$long, df_recs$lat, cex = 0.5, pch = 15) ## simple d.f.! 
plot(x = as(pt_shp, "Spatial"), col = 'blue', add = TRUE) 
```


#### `{ggplot2}` package

`{ggplot2}` is currently the best way to plot `{sf}` objects:
https://www.r-spatial.org/r/2018/10/25/ggplot2-sf.html.
The parameter `geom_sf()` is set here.

```{r ggplot-sf, fig.height=7.5}
ggplot(data = PA_shp) +
  geom_sf(fill = "chartreuse3", color = NA) +
  labs(x = "Longitude", y =  "Latitude",
       title = "Protected areas") +
  theme_minimal(base_size = 15) ## set custom plot style
```

Note that it does NOT work for `{sp}` objects (`SpatialPolygonsDataFrame`).


#### `{tmap}` package

*Static map*

The site ID is colour-coded here in a gradient

```{r tmap-sf, fig.height=7.5}
tmap_mode(mode = "plot")
tm_shape(shp = PA_shp[, 1]) + 
  tm_polygons(col = "SITE_ID", palette = grDevices::terrain.colors(5))
```


You can also plot several layers or highlighted details.
For example, we can plot a single selected protected area. Administrative area borders are black, protected areas green, and the single selected one is red.

```{r tmap-sp, fig.height=10.5}
tmap_mode(mode = "plot")

tm_shape(shp = Borneo_shp) + 
    tm_polygons(border.col = "black") +
  tm_shape(PA_shp[,1]) + 
    tm_polygons(border.col = "deepskyblue4") +
  tm_shape(PA_shp[1, ]) + 
    tm_polygons(border.col = "red")
```


Add spatial points (note: it does not work with `data.frames`) to the plot. 

```{r plot-new-sf-object, fig.height=8}
tmap_mode(mode = "plot")

tm_shape(shp = Borneo_shp) + 
    tm_polygons(col = "grey", border.col = "white") +
  tm_shape(shp = recs_sf) + 
    tm_dots(shape = 3, size = 0.25) +
  tm_shape(shp = pt_shp) + 
    tm_dots(col = "blue") 
```




*Interactive map*

```{r tmap-sf-interactive}
tmap_mode(mode = "view")
tm_shape(shp = PA_shp[, 1]) + 
  tm_polygons(col = "SITE_ID", palette = grDevices::terrain.colors(5))
```



## Saving vector data

Work with subsets, select Malaysia, save and plot as shapefile
with st_write():

```{r work-with-subsets, fig.height=10.5}
## select the protected areas of Malaysia only:
Mal_PA_shp <- subset(PA_shp, PA_shp$COUNTRY == 'Malaysia')

st_write(obj = Mal_PA_shp, 
         dsn = output_wd, 
         layer = 'ProtectedAreasMalaysia',
         driver = 'ESRI Shapefile', 
         delete_layer = TRUE)
```



## Geospatial calculation

This refers to the GIS functions of area calculations, distance calculations, spatial overlays and intersections. The new `{sf}` package has the same functionality, with functions starting with `st_`, e.g. `st_buffer()`, `st_intersection()` etc.

- https://geocompr.robinlovelace.net/spatial-operations.html
- https://r.geocompx.org/geometry-operations#clipping


### Area calculation

Returns the area in square meters for all features:

```{r sf-area}
# st_area(x = Borneo_shp) ## returns long vector
head(st_area(x = Borneo_shp))
```

Hint: you can also calculate the area for single features (e.g. one polygon).

```{r}
st_area(x = Borneo_shp[3, ]) ## for a single polygon
```

Example: Calculate area of Malaysia in km² 

```{r area-bornep}
Mal_Borneo_shp <- subset(Borneo_shp, Borneo_shp$NAME_0 == 'Malaysia')
head(st_area(x = Mal_Borneo_shp) / 1000000) ## or / 1e6

## better: use set_units to change the units from m^2 to km^2
Mal_Borneo_shp$area <- units::set_units(x = st_area(x = Mal_Borneo_shp), value = km^2)
head(Mal_Borneo_shp$area)
```




### CRS projection

Recap: If no CRS is assigned for a file, the CRS can be set with `st_crs()`. However, if a file 
has already a CRS, e.g. WGS84 (angular units, longitude and latitude), and you want to change into a projection with planar units (e.g. meters), use `st_transform()`.

```{r sf-transform}
Borneo_shp_moll <-  st_transform(Borneo_shp, c("+proj=moll +datum=WGS84"))
class(Borneo_shp_moll) # sf object, data.frame!
```

Plot it and have a look at the changes:

```{r mollweide-tmap, fig.height=10}
tmap_mode(mode = "plot")
tm_shape(shp = Borneo_shp_moll) + 
  tm_polygons(border.col = "blue") ## do you see the difference?
```

We can also use pretty `{ggplot2}` with `{sf}` objects:

```{r mollweide-ggplot, fig.height=9}
ggplot(Borneo_shp_moll) +
  geom_sf(color = "blue") +
  theme_minimal(base_size = 15) ## set custom plot style
```

Note the change in the area calculation!

```{r area-mollweide}
head(st_area(x = Borneo_shp_moll)) 
head(st_area(x = Borneo_shp))
```

Example: Add the area of a polygon as new column to a.t.

```{r area-polygon}

## create the column 'area_km2'
area_km2 <- set_units(x = st_area(x = Borneo_shp_moll, byid = TRUE), value = km^2)
Borneo_shp_moll = data.frame(Borneo_shp_moll, area_km2)
head(x = Borneo_shp_moll)
```

### Spatial overlay and intersections

#### Points and polygons with `st_intersection()`

Now we want to know which of our species observations (recs_sf) were taken in protected areas (PA_shp). For this, we use `st_intersection()`:

```{r spatial-overlay-1}
## retrieve the geometry (location) indices of PA_shp at
## the locations of sp_recs: which points are in PA_shp
nrow(recs_sf) ## 500
insidePA <- st_intersection(x = recs_sf, y = PA_shp) ## takes some seconds
nrow(insidePA) ## 11
```


#### Point and raster data with `extract()`

Then we want to know in which climatic zone we have observed the species 'recs_sf'. For this, we extract the information from the raster of mean annual temperature (ras_bio_asc_01) to the point locations of species observations:

```{r spatial-overlay-2}
# for a RASTER: extract mean ann. temp. from ras_bio_asc_01
# and add it to a.t.of the locations/ points
mean_t <- extract(x = ras_bio_asc_01, y = vect(recs_sf)) ## for {terra} we need to wrap the sf object into spatial vector with`vect()` 
recs_sf$mean_t <- mean_t$bio_asc_01
mean(x = recs_sf$mean_t) # hist(sp_recs_sf$mean_t)
```

#### Polygon and raster data with `extract()`

Finally, we want to know in which elevation range our protected areas are located. Extract elevation per PA and save average to attribute table of the shapefile/ vector data as a new column. The elevation raster was uploaded as ras_bio_asc_24 (see above, raster data section).

```{r extract-elevation-layer}
fewPA <- Mal_PA_shp[c(1:5), 1] ## select only 5 PAs to speed up computation

## returns a data.frame — each ID contains multiple elevation raster cells (ras_bio_asc_24).
## the shapefile has to be turned into a spatial vector
tmp <- extract(x = ras_bio_asc_24, y = vect(fewPA), xy = TRUE) 
str(tmp) ## overview over the 'data.frame' object. It should have 5 IDs for example. Let's check:
unique(tmp$ID)

## As a protector area feature of the shapefile comprises several elevation raster cells,
## they are all appended in the extracted data.frame
head(tmp)

## use tapply (see course 1 - R Intro) to check the values. 
## The protected area with ID = 1 seems to comprise high elevation
PA_elev <- tapply(X=tmp$bio_asc_24, INDEX = tmp$ID, FUN = mean)
PA_elev
## you can either transform this info to a data.frame....
PA_elev <- data.frame(PA_elev)

```

Append mean elevation to the shapefile:
```{r appenad-mean-elevation}
## ...or use function 'aggregate()'. this returns a `data.frame`. 
## The elevation info is in column 'x'
mean_tmp <- terra::aggregate(tmp$bio_asc_24, by = list(Category = tmp$ID), FUN = mean) 

## Since both objects, the shapefile 'fewPA' and the data.frame 'mean_tmp' (or 'PA_elev') 
## are ordered by ID,
## you can directly append the information to the attribute table of 'fewPA'
fewPA$mean_elevation <- mean_tmp$x
#fewPA$mean_elevation <- PA_elev ## alternatively

fewPA
```



# Spatial data sources in the web

We have now also completely outsourced this chapter onto our coding wiki website:


https://ecodynizw.github.io/posts/r-spatial-data/



## `{rnaturalearth}`

[NaturalEarth](http://www.naturalearthdata.com) (http://www.naturalearthdata.com) is a public domain map data set that features vector and raster data of physical and cultural properties. It is available at 1:10m, 1:50m, and 1:110 million scales.

[`{rnaturalearth}`](https://docs.ropensci.org/rnaturalearth) (https://docs.ropensci.org/rnaturalearth) is an R package to hold and facilitate interaction with NaturalEarth (ne_...) map data. 

After loading the package, you can for example quickly access shapefiles of all countries that are already projected and can be stored as either `sp` or `sf` objects:

```{r data-rnaturalearth}
library(rnaturalearth)

## store as sf object (simple features)
world <- ne_countries(returnclass = "sf")
class(world)

sf::st_crs(world)[1]
```

This country data set (which is actually not downloaded but stored locally by installing the package) already contains several useful variables, mostly referring to different naming conventions (helpful when joining with other data sets), to identify continents and regions, and also some information on population size, GDP, and economy:

```{r names-world-rnaturalearth}
names(world) ## takes some seconds to compute
```

We can quickly plot it:

```{r plot-world-rnaturalearth, fig.height=3.5}
ggplot(world) + 
  geom_sf(aes(fill = economy)) + 
  coord_sf(crs = "+proj=eqearth") +
  theme_void()
```

**NOTE:** Unfortunately, NaturalEarth is using [weird *de-facto* and *on-the-ground rules* to define country borders which do not follow the borders the UN and most countries agree on](https://github.com/nvkelso/natural-earth-vector/issues/391). For correct and official borders, please use the {rgeoboundaries} package (see below).

You can specify the scale, category and type you want as in the examples below.

```{r glacier-rnaturalearth, fig.height=4.5, fig.show="hold"}
glacier_small <- ne_download(type = "glaciated_areas", category = "physical", 
                             scale = "small", returnclass = "sf")

glacier_large <- ne_download(type = "glaciated_areas", category = "physical", 
                             scale = "large", returnclass = "sf")

ggplot() + 
  geom_sf(data = world, color = "grey80", fill ="grey80") +
  geom_sf(data = glacier_small, color = "grey40", fill = "grey40") + 
  coord_sf(crs = "+proj=eqearth") +
  theme_void()

ggplot() + 
  geom_sf(data = world, color = "grey80", fill ="grey80") +
  geom_sf(data = glacier_large, color = "grey40", fill = "grey40") +
  coord_sf(crs = "+proj=eqearth") + 
  theme_void()
```


## `{rgeoboundaries}`

The [`{rgeoboundaries}` package](https://github.com/wmgeolab/rgeoboundaries) uses the Global Database of Political Administrative Boundaries that provide generally accepted political borders. The data are licensed openly. 

```{r rgeoboundaries-world}
#install.packages("remotes")
#remotes::install_github("wmgeolab/rgeoboundaries")
## you might need to install 'hoardr' manually

library(rgeoboundaries)
## you might be asked to create a cache folder -> click yes


## the following takes a while to load. Be patient.
gb_adm0() ## political boundary file

## plotting takes a long time!!!
ggplot(gb_adm0()) + 
  geom_sf(color = "grey40", lwd = .2) + 
  coord_sf(crs = "+proj=eqearth") +
  theme_void()
```

Lower administrative levels are available as well, e.g. in Germany adm1 represents federal states ("Bundesländer"), adm2 districts ("Kreise") and so on.

Let's plot the admin 1 levels for the DACH countries:

```{r rgeoboundaries-country}
dach <- gb_adm1(c("germany", "switzerland", "austria"), type = "sscgs")

ggplot(dach) +
  geom_sf(aes(fill = shapeGroup)) +
  scale_fill_brewer(palette = "Set2") +
  theme_void()
```


## `{osmdata}`

[OpenStreetMap](https://www.openstreetmap.org) (https://www.openstreetmap.org) is a collaborative project to create a free editable geographic database of the world. The geodata underlying the maps is considered the primary output of the project and is accessible from R via the `{osmdata}` package.

We first need to define our query and limit it to a region. You can explore the features and tags (also available as information via OpenStreetMap directly).

```{r data-osmdata}
library(osmdata)

## explore features + tags
head(available_features())
head(available_tags("craft"))

## building the query, e.g. beekeepers
beekeeper_query <- 
  ## you can automatically retrieve a bounding box (pr specify one manually)
  getbb("Berlin") %>%
  ## build an Overpass query
  opq() %>%
  ## access particular feature
  add_osm_feature("craft", "beekeeper")
  
## download data
sf_beekeepers <- osmdata_sf(beekeeper_query)
```

Now we can investigate beekeepers in Berlin:

```{r plot-osmdata, fig.height=5.5}
names(sf_beekeepers)

head(sf_beekeepers$osm_points)

beekeper_locations <- sf_beekeepers$osm_points

gb_ber <- gb_adm1(c("germany"), type = "sscgs")[3,] # the third element is Berlin

ggplot(beekeper_locations) + 
  geom_sf(data = gb_ber) +
  # geom_sf(data = d6berlin::sf_berlin) + ## alternative to geoboundaries, but d6berlin needs to be loaded first
  geom_sf(size = 2) +
  theme_void()
```

## `{elevatr}`

The [`{elevatr}`](https://github.com/jhollist/elevatr/) (https://github.com/jhollist/elevatr/) is an R package that provides access to elevation data from AWS (Amazon Web Services) Open Data Terrain Tiles and the Open Topography Global data sets API (application programming interface) for raster digital elevation models (DEMs).

We first need to define a location or bounding box for our elevation data. This can either be a data frame or a spatial object. We use an `sf` object which holds the projection to be used when assessing the elevation data:

```{r bbox-elevatr, fig.height=4.5}
library(elevatr)

## manually specify corners of the bounding box of the US
bbox_usa <- data.frame(x = c(-125.0011, -66.9326), 
                   y = c(24.9493, 49.5904))

## turn into spatial, projected bounding box
sf_bbox_usa <- st_as_sf(bbox_usa, coords = c("x", "y"), crs = 4326)
```

Now we can download the elevation data with a specified resolution z (ranging from 1 to 14 with 1 being very coarse and 14 being very fine).

```{r data-plot-elevatr, fig.height=5.2}
elev_usa <- get_elev_raster(locations = sf_bbox_usa, z = 5)

plot(elev_usa)
```

<br>

<details><summary> Optional - composite plots </summary>

Composite plots: plotting several layers and data types

*Simple composite plot*

Plot the hillshade (3D relief) and add temperature colours on top: alpha value 
gives semi-transparency. The extent is plotted as a red box, and the centroid coordinates of the raster cells are plotted as points. 

```{r simple-composite-plot}
plot(Bor_hs, col = grey(0:100/100), legend = FALSE)
plot(ras_bio_asc_24, col = terrain.colors(25, alpha = 0.3), add = TRUE)
points(crds(ras_bio_asc_01_cr), cex = 0.1, pch = '+') 
plot(ext(ras_bio_asc_01_cr), add = TRUE, col = 'red')
```


*Composite plot with `{tmap}`*

In the following, we will create a `SpatialPointDataFrame` from the
small clipped/ cropped raster  with the `{sf}` package and plot it on top of the 
hillshade. Use the possibility of selecting/ disregarding different layers 
(layer icon on the left).

```{r points-sf}
hillsh <- Bor_hs

# make sf object from coordinates of the raster
ras_bio_asc_01_cr_sf <- st_as_sf(
  data.frame(crds(ras_bio_asc_01_cr)), 
  coords = c("x", "y"), ## define columns for the coordinates
  crs = 4326, ## define crs, 4326 is the EPSG code
  sf_column_name = "geometry" ## sf needs a geometry column and you have to name it
)

# interactive plot
tmap_mode(mode = "view")

tm_shape(shp = hillsh, raster.downsample = TRUE)  +  
    tm_raster(palette = "Greys") +
  tm_shape(shp = ras_bio_asc_24, raster.downsample = TRUE) + 
    tm_raster(palette = grDevices::topo.colors(20),alpha = 0.3) +
  tm_shape(shp = ras_bio_asc_01, raster.downsample = TRUE) + 
    tm_raster(palette = grDevices::rainbow(10), alpha = 0.3) +
  tm_shape(shp = ras_bio_asc_01_cr_sf) + 
  tm_dots(shape = 20, size = 0.01) 
```

What do the shape-arguments mean, e.g. `shape = 20`? Have a look here at the symbols:
https://ggplot2.tidyverse.org/articles/ggplot2-specs.html?q=shape#sec:shape-spec


Unfortunately, in `{tmap}` you can only use `shape = 1` and `shape = 20`, 
only circles are plotted.



```{r static-sf-hillshade}
# static plot  
tmap_mode(mode = "plot")

tm_shape(shp = hillsh, raster.downsample = TRUE) + 
    tm_raster(palette = "Greys") +
  tm_shape(shp = ras_bio_asc_24, raster.downsample = TRUE) +
    tm_raster(palette = grDevices::terrain.colors(10), alpha = 0.3) +
  tm_shape(shp = ras_bio_asc_01_cr_sf) + 
  tm_dots(shape = 1, size = 0.05) 
```
 


*An Advanced Map with `{tmap}`*

At the end, an example of a beautiful map, created with `tmap`: 

```{r tmap-beauty, fig.width=12, fig.height=12}
tmap_mode(mode = "plot")

tm_shape(shp = hillsh) + 
  ## hillshading
  tm_raster(palette = "Greys",
            legend.show = FALSE, 
            alpha = 0.75) +
  ## topographical model
  tm_shape(shp = ras_bio_asc_24) + 
  tm_raster(palette = terrain.colors(25),
            alpha = 0.2, 
            legend.show = FALSE) +
  ## rivers
  tm_shape(shp = River_shp) + 
  tm_lines(col = "dodgerblue3") +
  ## protected areas
  tm_shape(shp = PA_shp) + 
  tm_polygons(border.col = "white", 
              alpha = 0) +
  ## locations
  tm_shape(shp = recs_sf) + 
  tm_dots(shape = 16, 
          size = 0.3) +
  tm_shape(shp = insidePA) + 
  tm_dots(col = "red",
          size = 1,
          shape = 3) +
  ## styling
  tm_layout(title = "END OF SESSION", 
            title.color = "darkgrey",
            title.position = c(0.05, 0.9),
            title.size = 2)
```

End optional.

</details>



# Recap: the most important functions for spatial data

TL;DR ? (too long didn't read?). Then at least remember the following most important commands for loading, projecting and saving spatial data. 

## Load spatial data

```{r, eval=FALSE}
myraster       <- terra::rast()
myshapefile    <- sf::st_read()
myxydataframe  <- sf::st_as_sf()
```

## Assign CRS to or project spatial data into another CRS

```{r, eval=FALSE}
## Set/ assign the CRS if missing
crs(myraster)  <- "+init=epsg:4326" ##assign if raster comes without CRS
st_crs(myshapefile, 'EPSG:3085')

## project it
myraster_proj  <- terra::project(myraster, 'EPSG:3085') ##example
myshapefile_prof <- sf::st_transform(myshapefile, 3085)
```


## Save spatial data

```{r, eval=FALSE}
terra::writeRaster() ## SpatRaster
sf::st_write()       ## vector data
```


# <span class='exercise'>Course 2 Exercise 1</span>

**Please hand in the R-Script and the plots. Please add your name or name of group to the file/script names.**

For example: myplotname_course2_ex1_yourlastname_yourfirstname.pdf/ or: .png/ or: .html and Rscript_course2_ex1_yourlastname_yourfirstname.Rmd/ or: .R

**Revisit the data set from course 1 on wild boar observations in Berlin: `data_wb_melden_en.csv`. 
(it is here: `....\d6_teaching_collection\data\data_berlin\animal_data`).

Now, we want to study the spatial patterns of the wild boar observations. We may hypothesize that wild boar observations are also related to local differences in weather. Answer the following question using spatial data sets and visualizations:**

* **Question 1.1) Were wild boar with many piglets seen more often in warm parts of the city?**
* **Question 1.2) Were wild boars more often observed at colder spots of the city during sunny weather?**
* **Question 1.3) *Additional question for the fast ones:* Were large groups of wild boar more frequently seen in areas providing a dense tree cover?**

Follow these steps to answer the questions:

* a. Load the wild boar data (`data_wb_melden_en.csv`) and spatial data on temperature in Berlin (`summer_temp_100m_3035.asc` in `data_berlin`). Remember to set the correct CRS to the raster! (Hint: we need the Lambert Azimuthal Equal Area (LAEA) projection for Europe. Tip: always save the CRS as EPSG code to the filename ;-) )
* b. Turn the wild boar data into a simple features object.  Remember to set the correct CRS (the wild boar locations were collected in WGS 84) and to transform it to the same CRS as the raster afterwards!
* c. Inspect both spatial data sets by plotting the temperature raster with the wild boar locations on top using the R basic plot function. The locations should match the map (if not something went wrong when setting the CRS; check if they are the same).
* d. Select one of the temperature layers and extract the values for each wild boar location. 
* e. Create a plot that visualizes the temperature at each wild boar observation with 3 or more piglets (y axis) for each number of piglets (e.g. make a boxplot and plot the raw data on top). 
* f. Create a new variable that holds the weather category as either "sunny" or "other".
* g. Visualize the temperature at each wild boar observation (y axis) for sunny and other weather (box and whisker plot + raw data). 
* h. Save the wild boar observations with the local temperature information as an .Rds file.


For the additional question: 

* i. Load the tree cover data set (`tree_cover_density_2012_100m_3035.asc` in `data_berlin`).
* j. Inspect the data set by plotting the raster using the R basic plot function.
* k. Extract the tree cover within a buffer of 100m around each wild boar location (hint: use the help to inspect the arguments of `extract()`). 
* l. Create a boxplot that shows the tree cover (y axis) based on the group size.

<br><hr><br>

**Session Info**

```{r sessionInfo, echo=FALSE}
sessionInfo()
```
