knitr::opts_chunk$set(echo = TRUE, fig.align = 'center', fig.width = 6, fig.height = 6)
library(knitr)
library(vegan)
library(iNEXT)
library(sads)
library(tidyverse)
library(terra)
library(here)
envir   <- read.csv(here('data','data_berlin','animal_data','transects_allenvir_100m.csv'))
# Export dataframe of species abundance and environmental variables for each site
species <- read.csv(here('data','data_berlin','animal_data','birds_berlin_exercise_planillo2021.csv'))
envir   <- read.csv(here('data','data_berlin','animal_data','transects_allenvir_100m.csv'))
library(knitr)
library(vegan)
library(iNEXT)
library(BAT)
library(psych)
library(dplyr)
library(ggplot2)
library(terra)
library(here)
birds <- read.csv(here("data","data_berlin","animal_data",
"birds_berlin_exercise_planillo2021.csv") )
## look at the data
ncol(birds)
head(birds)
str(birds)
sites <- birds$site
birds.data <- birds[,-71] # remove site from data
rownames(birds.data) <- birds$site
str(birds.data)
envir <- read.csv(here("data","data_berlin","animal_data","birds_transects_allenvir_100m.csv"))
head(envir)
str(envir)
envir <- read.csv(here("data","data_berlin","animal_data","birds_transects_allenvir_100m.csv"))
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
fig.width = 9, fig.height = 6, dev = "ragg_png")
#knitr::opts_knit$set(root.dir = 'C:/Users/kramer/PopDynIZW Dropbox/Steph Kramer/_GitHub')
# Chunk 2
### The packages (repetition) ###
library(here)
library(sp)
library(sf)
library(tmap)
library(dismo)
library(terra)
library(GISTools)
install.packages("GISTools")
### The packages (repetition) ###
library(here)
library(sp)
library(sf)
library(tmap)
library(dismo)
library(terra)
#  library(GISTools)
library(rgdal)
library(maptools)
library(viridis)
library(rgeos)
library(rgl)
# library(rasterVis)
library(unmarked)
library(spatstat)
## check that the package raster is detached!
# detach(package:raster)
### The workspace  (repetition) ###
getwd() # you can also use the package 'here()'
# my data are outside my course-folder, therefore I have to do it the old-fashioned way.
root_wd <- here::here()
# relative to work-wd
maps_wd <- paste(root_wd,"/","data/data_borneo/geo_raster_current_asc",sep='') # or:
vecs_wd <- here::here("data","data_borneo","geo_vector") # shapefile
recs_wd <- here::here("data","data_borneo","animal_data") # location data
# the output folder should have been created by you during Tutorial 2 'R goes spatial'.
# It should contain the hillshade.asc
output_wd <- here::here("output")
setwd(output_wd) ## set to the OUTPUT folder!
getwd() # check
### Data import - Load spatial data (repetition) ###
ras1 <- terra::rast(x = paste(maps_wd,'/bio_asc_01.asc',sep=''))
# assign the projection (crs - coordinate reference system)
# ras1@crs <- CRS("+proj=longlat +datum=WGS84") ## not needed in terra!
ras24 <- terra::rast(here("data","data_borneo", "geo_raster_current_asc", "bio_asc_24.asc")) #DEM
ras42 <- terra::rast(x = here(maps_wd,"bio_asc_42.asc")) # land use
hillsh <- terra::rast(x = paste(maps_wd,'/borneo_hillshade.asc',sep=''))
plot(hillsh)
# the list.files command is very helpful to check what is in the folders
# use 'pattern' for searching for special file types, here .asc-files:
files <- list.files(path= maps_wd, pattern='.asc$',
full.names=TRUE )
files # these are just names! To load them as spatial objects, use raster() or stack()
# predictors <- c(files[c(9,12,22,24)]) # for full data set
predictors <- c(files[c(1,3,6,7)]) # note that I only load 4 rasters: for github repository data
predictors
## note that I only load 4 rasters:
# predictors <- c(files[c(9,12,22,24)]) # for full data set
predictors <- rast(x = c(files[c(1,3,6,7)]) ) # for github repository data
predictors
plot(predictors, col = viridis(100)) # might take some time depending on your computer
## note that I only load 4 rasters:
# predictors <- c(files[c(9,12,22,24)]) # for full data set
predictors <- rast(x = c(files[c(1,2,6,7)]) ) # for github repository data
plot(predictors, col = viridis(100)) # might take some time depending on your computer
## note that I only load 4 rasters:
# predictors <- c(files[c(9,12,22,24)]) # for full data set
predictors <- rast(x = c(files[c(1,4,6,7)]) ) # for github repository data
plot(predictors, col = viridis(100)) # might take some time depending on your computer
## note that I only load 4 rasters:
# predictors <- c(files[c(9,12,22,24)]) # for full data set
predictors <- rast(x = c(files[c(1,5,6,7)]) ) # for github repository data
plot(predictors, col = viridis(100)) # might take some time depending on your computer
### Read in some Shapefiles (repetition) ###
## package sf (new and maintained)
## Borneo outline polygon
Borneo_shp_sf <- st_read(dsn = vecs_wd,
layer = "borneo_admin",
stringsAsFactors = FALSE)[,c(1:3,5,7,17,18)]
# Protected areas (PA) polygon
PA_shp_sf <-  st_read(dsn = vecs_wd,
layer = "Bor_PA",
stringsAsFactors = FALSE)[, c(1:4)]
# Rivers lines
River_shp_sf <- st_read(dsn = vecs_wd,
layer = "sn_100000",
stringsAsFactors = FALSE)
### The spatial point data (species records) (repetition) ###
# filename
spec_pt_filename <- paste(recs_wd,'/','MyNewSpecies.csv', sep='')
spec_pt_filename
# you can play also with other files
#spec_pt_filename <- paste(recs_wd,'/','DHOsim.csv',sep='')
#spec_pt_filename <- paste(recs_wd,'/','PPLsim.csv',sep='')
# read the file
sp_recs <- read.csv(file = spec_pt_filename, header=TRUE, sep=',')
#convert it to spatial object (sf here)
sp_recs_sf <- st_as_sf(x = sp_recs,
coords = c("long","lat"), # columns  for the coordinates
crs = 4326, # define crs, 4326 is the EPSG code
sf_column_name = "geometry",
remove=F) # sf needs a geometry column and you have to name it
# load a second species
river_pt_filename <- here(recs_wd,"RIVERsim.csv")
river_recs        <- read.csv(file = river_pt_filename, header=TRUE, sep=',')
river_recs_sf     <- st_as_sf(x = river_recs,
coords = c("long", "lat"),
crs = 4326,
sf_column_name = "geometry")
### Plot to get an impression ###
plot(ras42, col=grey.colors(20))
plot(PA_shp_sf$geometry,border='green', lwd=1.8, add=T)
plot(sp_recs_sf$geometry, pch= '*',cex=1,col='deeppink',add=T)
text(112, 6, 'Starting with SDMs', cex=1.5, col= 'red')
plot(River_shp_sf[,3], col='dodgerblue4', add=T)
# workaround for slow computers. First, aggregate the 1 kmÂ² resolution into 50*50 km
agg_pred <- aggregate(x=predictors,fact=50,FUN=mean)
plot(agg_pred)
terra::pairs(agg_pred, method = 'spearman')
# Plot the differences (residuals) between the rasters:
diff <- terra::focalPairs(x = agg_pred, w = 3, 'pearson', na.rm = TRUE)
plot(diff)
head(Borneo_shp_sf)
plot(Borneo_shp_sf[,3]) # column 3 is NAME_0 = main country names
Mal_ras <- rasterize(x=Borneo_shp_sf[Borneo_shp_sf$NAME_0 %in%
c("Brunei","Malaysia"),], y=ras24, field=1,
background=0.1)
plot(Mal_ras)
Sab_ras <- rasterize(x=Borneo_shp_sf[Borneo_shp_sf$NAME_1 == 'Sabah',],
y=ras24, field=1, background=0.1)
PA_ras <- rasterize(x=PA_shp_sf, y=ras24, field=1, background=0.1)
### Crosscheck with plot
par(mfrow=c(1,2))
plot(Sab_ras)
plot(PA_ras) #n.b.: only 1 and small values, no NA
par(mfrow=c(1,1))
par(mfrow=c(1,1))
plot(ras24_300)
ras24_300 <- ras24 <= 300
plot(ras24_300)
bias_tmp <- ras24_300 + Sab_ras + Mal_ras + PA_ras
bias_tmp
plot(bias_tmp)
# get the maximum value in the layer, standardize it and round to two decimals
maxval <- max(values(bias_tmp),na.rm=T)
bias_tmp2 <- bias_tmp/maxval
bias_tmp3 <- round(bias_tmp2, digits=2)
## same as in one go:
bias1 <- round(bias_tmp/max(values(bias_tmp),na.rm=T),digits=2)
table(values(bias1))
### in case of having 0 somewhere:
bias1[values(bias1 == 0)] <- 0.01 # because MaxEnt
# does not take 0!
table(values(bias1))
terra::compareGeom(ras24,bias1) # the same?
terra::compareGeom(ras24,bias1) # the same?
check for the length of the NODATA values:
# Are they really the same???
length(which(!is.na(values(bias1))))
length(which(!is.na(values(ras24))))
### Plot the bias file
plot(bias1, col = viridis(7)) #or col = grey.colors(7)
output_wd
# new argument 'recursive' means, that also subfolders are checked!
infiles <- list.files(path=paste(output_wd,'/MaxEntRes',
sep=''),pattern='_avg.asc$',
full.names=TRUE,recursive=TRUE )
infiles
me_stack <- rast(infiles[c(1:4)])
# name sequence according to infiles list above
names(me_stack) <- c('curr_noBias','fut_noBias',
'curr_withBias','fut_withBias')
plot(me_stack,col=viridis(100)) # note: I might use a different example than you did in MaxEnt
boxplot(me_stack,layers = c(1,3,2,4),notch=T,outline=F)
me_res <- list.files(path=paste(output_wd,'/MaxEntRes',sep=''),
pattern='maxentResults.csv',
full.names=TRUE,recursive=TRUE )
me_res
store_res <- lapply(me_res,FUN=read.csv) #store as list obj.
## Check the following out:
# head(store_res) # list object with 2 slots
# str(store_res)
# store_res[[1]]
zename<-'X10.percentile.training.presence.logistic.threshold' # check if the column name is the same !!!!!
zecol <-which(colnames(store_res[[1]]) == zename)
zecol
## a little head twister:
## access each element of your list, which is a whole dataset with store_res[[1]]
## and inside this list object = data.frame, access the element of
## the last row (nrow), and the column zecol] containing the threshold value
t_noBias   <- store_res[[1]][nrow(store_res[[1]]),zecol]
t_withBias <- store_res[[2]][nrow(store_res[[2]]),zecol]
t_noBias #the thresholds
t_withBias
all_bias <- rep(c(t_noBias,t_withBias), each=2)
all_bias
binary_thresh <- me_stack >= all_bias
plot(binary_thresh)
test05 <- me_stack >= 0.5 # check result with fixed threshold of default cut-off
plot(test05)
# Extract relative probability values inside protected areas PAs
# check if overlay correct - only works when you have NOT aggregated the maps
compareRaster(PA_ras,me_stack[[1]])
?compareRaster
# Extract relative probability values inside protected areas PAs
# check if overlay correct - only works when you have NOT aggregated the maps
all.equal(PA_ras,me_stack[[1]])
# Extract relative probability values inside protected areas PAs
# check if overlay correct - only works when you have NOT aggregated the maps
compareGeom(PA_ras,me_stack[[1]])
ex <- which(values(PA_ras)==1)
# ex # gives Pointer to elements/ Index
ex_stack <- extract(x=me_stack, y=ex)
head(ex_stack)
boxplot(ex_stack,na.rm=T)
ex_binary <- extract(x=binary_thresh, y=ex)
head(ex_binary)
## In the following, we are summing the cells with 'TRUE'
ex_binary[1:2,]; colSums(ex_binary,na.rm=T) # 2 cmnds in line with ; !
ex_binary[1:2,]
head(ex_binary)
ex_binary <- extract(x=binary_thresh, y=ex)
head(ex_binary)
## In the following, we are summing the cells with 'TRUE'
colSums(ex_binary,na.rm=T)
infiles # remember, out folder content
# chose one:
my_MaxEnt_avg_Map <- raster(infiles[1])
# chose one:
my_MaxEnt_avg_Map <- rast(infiles[1])
my_MaxEnt_avg_Map
# plot
plot(my_MaxEnt_avg_Map,col=viridis(100))
#install.packages('gdistance')
library(gdistance)
# Set start and end points: centers of the first two PA polygons
start <- gCentroid(PA_shp[1,1], byid=FALSE, id = NULL)
# Set start and end points: centers of the first two PA polygons
start <- gCentroid(PA_shp_sf[1,1], byid=FALSE, id = NULL)
PA_shp <- as(PA_shp_sf, "Spatial")
# Set start and end points: centers of the first two PA polygons
start <- gCentroid(PA_shp[1,1], byid=FALSE, id = NULL)
end   <- gCentroid(PA_shp[2,1], byid=FALSE, id = NULL)
# Several commands in one line when separated by ';':
plot(me_stack[[1]]); points(start); points(end)
# Clip raster to save computation time
cr_extent <- c(114,117,3,6.5)
me_cr <- crop(x=me_stack[[1]],y=cr_extent)
plot(me_cr); points(start,pch=15); points(end,pch=15)
### Necessary calculations
# Calculate the transition layer
trans <- transition(x = me_cr,
transitionFunction = mean,
directions = 4,
symm = F)
me_cr_raster <- as.raster(me_cr)
me_cr_raster
plot(me_cr_raster)
trans <- transition(x = me_cr_raster,
transitionFunction = mean,
directions = 4,
symm = F)
me_stack
me_cr
me_cr_raster
me_cr_raster <- raster(me_cr)
me_cr_raster
trans <- transition(x = me_cr_raster,
transitionFunction = mean,
directions = 4,
symm = F)
class(trans)
# Calculate the shortest weighted connection
sPath <- shortestPath(trans, start, end,
output="SpatialLines")
sPath
# Calculate the length of the path
costDistance(trans, start, end) #units?
# Make a plot
plot(me_cr,col=viridis(100)); points(start,pch=15); points(end,pch=15)
# Make a plot
plot(me_cr,col=viridis(100)); points(start,pch=17,col='white'); points(end,pch=15, col='white')
lines(sPath,lwd=1, col= 'red'); plot(PA_shp, border='white', lwd=0.5,add=T)
# where does the animal corridor intersect rivers?
# in sf package
River_inter1 <- st_intersection(x = River_shp_sf, y = as(sPath, "sf"))
River_inter1
plot(sPath,lwd=3); plot(PA_shp,border='grey',lwd=1,add=T)
plot(River_shp,col='blue',lwd=2,add=T)
plot(River_shp_sf,col='blue',lwd=2,add=T)
plot(River_shp_sf@geometry,col='blue',lwd=2,add=T)
plot(River_shp_sf,col='blue',lwd=2,add=T)
plot(River_inter1,col='red',lwd=4,add=T); box()
######## currently out of order
# Which connections intersect the PAs?
PA_inter1 <- st_intersection(x = PA_shp_sf, y = as(sPath, "sf"))
st_make_valid(PA_shp_sf)
######## currently out of order
# Which connections intersect the PAs?
PA_inter1 <- st_intersection(x = PA_shp_sf, y = as(sPath, "sf"))
st_make_valid(sPath)
sPath
y = as(sPath, "sf")
y
PA_shp_sf
PA_inter1 <- gIntersection(x = PA_shp, y = sPath)
?gIntersection
PA_shp_sp <- as(PA_shp_sf, "Spatial")
# Set start and end points: centers of the first two PA polygons
start <- gCentroid(PA_shp_sp[1,1], byid=FALSE, id = NULL)
end   <- gCentroid(PA_shp_sp[2,1], byid=FALSE, id = NULL)
# Several commands in one line when separated by ';':
plot(me_stack[[1]]); points(start); points(end)
# Clip raster to save computation time
cr_extent <- c(114,117,3,6.5)
me_cr <- crop(x=me_stack[[1]],y=cr_extent)
plot(me_cr); points(start,pch=15); points(end,pch=15)
# but first, we need to backtransform the SpatRaster {terra}-Object
# into a RasterLayer {raster}-Object:
me_cr_raster <- raster(me_cr)
trans <- transition(x = me_cr_raster,
transitionFunction = mean,
directions = 4,
symm = F)
class(trans)
# Calculate the shortest weighted connection
sPath_sp <- shortestPath(trans, start, end,
output="SpatialLines")
sPath_sp
# where does the animal corridor intersect rivers?
# in sf package
River_inter1 <- st_intersection(x = River_shp_sf, y = as(sPath_sp, "sf"))
plot(sPath_sp,lwd=3); plot(PA_shp_sp,border='grey',lwd=1,add=T)
plot(River_shp_sf,col='blue',lwd=2,add=T)
plot(River_inter1,col='red',lwd=4,add=T); box()
######## currently out of order
# Which connections intersect the PAs?
PA_inter1 <- st_intersection(x = PA_shp_sf, y = as(sPath_sp, "sf"))
PA_inter1 <- gIntersection(x = PA_shp_sp, y = sPath_sp)
PA_inter1 <- gIntersection(PA_shp_sp, sPath_sp)
plot(sPath_sp,lwd=3); plot(PA_shp_sp,border='blue',lwd=2,add=T)
lines(PA_inter1,col='red',lwd=4); box()
### Save new line as shapefile
cp_line <- SpatialLinesDataFrame(sl=sPath,
data = data.frame(name = c(1:length(sPath@lines))))
writeOGR(obj=cp_line,dsn=output_wd,layer='costpath_line',
driver = 'ESRI Shapefile', overwrite = TRUE)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
dev = "ragg_png", fig.width = 9, fig.height = 6, dpi = 600, retina = 1)
Sys.setlocale("LC_TIME", "C")
# Chunk 2: libraries
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center', fig.width = 6, fig.height = 6)
library(knitr)
library(vegan)
library(iNEXT)
library(sads)
library(tidyverse)
library(terra)
library(here)
# Chunk 3
data(moths)
moths
?moths
# Chunk 4: octaves
moths.oc <- octav(moths)
moths.oc
plot(moths.oc)
# Chunk 5: RAD
# for the moths data
moths.rad <- rad(moths)
plot(moths.rad, ylab="Number of individuals")
# Chunk 6
# build the model
moths.ge <- fitsad(x=moths, sad="geom") # geometric distribution
moths.ls <- fitsad(x=moths, sad="ls") # log series distribution
moths.ln <- fitsad(x=moths, sad="lnorm") #log-normal distribution
# get rank abundance objects
moths.ge.rad <- radpred(moths.ge)
moths.ls.rad <- radpred(moths.ls)
moths.ln.rad <- radpred(moths.ln)
# Plot the curves
plot(moths.ln.rad)
plot(moths.ln.rad, xlab = "Rank", ylab = "Abundance", log = "y",
type = "l", col = "green", lty = 1, lwd = 6)
# We can superimpose the curve to the rank plot
plot(moths.rad)
lines(moths.ge.rad, col="red")
lines(moths.ls.rad, col="blue")
lines(moths.ln.rad, col="green")
legend("topright",c("Geometric", "Logseries", "lognormal"),lty=1, col=c("red", "blue", "green"))
## looking at the fits
logLik(moths.ge)
logLik(moths.ls)
logLik(moths.ln)
# Chunk 7: shannon_birds
birds1 <- data.frame(Species = c('BlueTit', 'Robin', 'Magpie',
'GreatTit'),
Abundance = rep(9, 4))
birds1
## now let us get the pi, ln(pi), N and S to calculate Shannon index
N <- sum(birds1$Abundance)
S <- nrow(birds1)
pi <- birds1$Abundance/N
lnpi <- log(pi)
H <- -sum(pi*lnpi)
H
# Chunk 8: shannon_vegan
# 1. transpose the data
birds1.transpose <- as.data.frame(t(birds1[, -1]))
colnames(birds1.transpose) <- birds1$Species
birds1.transpose
# Get diversity value
?diversity
H_vegan <- diversity(birds1.transpose, index = "shannon")
H_vegan
# Chunk 9: shannon_vs_hill
# We create a second community with no species in common with the first one
birds2 <- data.frame(Species = c('Sparrow', 'Dove', 'Crow'),
Abundance = c(4,5,20))
birds2
# the transpose matrix for the analysis
birds2.transpose <- as.data.frame(t(birds2[, -1]))
colnames(birds2.transpose) <- birds2$Species
birds2.transpose
# Both communities in the same table
# transpose data and get sums
birds.both <- merge(birds1, birds2, by = 'Species', all = T)
birds.both$Abundance.x[is.na(birds.both$Abundance.x)] <- 0
birds.both$Abundance.y[is.na(birds.both$Abundance.y)] <- 0
birds.both
birds.all <- rowSums(birds.both[,2:3])
birds.all
both.trans <- as.data.frame(t(birds.both[, -1]))
colnames(both.trans) <- birds.both$Species
rownames(both.trans) <- c("birds1", "birds2")
both.trans
all.trans <- colSums(both.trans)
# shannon diversity for each sample and for the sum
H1 <- diversity(both.trans, index = "shannon")
H2 <- diversity(all.trans, index = "shannon")
H1
H2
# Hill number order 1 (library iNEXT)
HN1.birds1 <- iNEXT(birds1$Abundance)
HN1.birds1$AsyEst
HN1.birds2 <- iNEXT(birds2$Abundance)
HN1.birds2$AsyEst
HN1.birdsboth <- iNEXT(birds.all)
HN1.birdsboth$AsyEst
# Chunk 10: load_inext_data
data(spider)
str(spider)
# Chunk 11: run_inext_q0
example1 <- iNEXT(spider, q = 0, datatype = "abundance")
example1$DataInfo
#Show a summary of the data with diversity estimates in rarefied and extrapolated samples
example1$iNextEst
# show asymptotic estimates
example1$AsyEst
# Chunk 12
# We define the number of samples size that we want to use for estimation
m <- c(1, 50, 100, 200, 400)
example2 <- iNEXT(spider, q = c(0,1,2), datatype = "abundance", size = m)
example2$iNextEst
# Chunk 13
ggiNEXT(example1, type=1) # Curve for sample size
# Chunk 14
ggiNEXT(example2, type=1, facet.var="site")
?iNEXT
?ggiNEXT
ggiNEXT(example2, type=1, facet.var="Assemblage")
